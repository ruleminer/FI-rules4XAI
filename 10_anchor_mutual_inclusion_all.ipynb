{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "from rmatrix.classification import RMatrixClassifier\n",
    "from decision_rules.serialization.utils import JSONSerializer\n",
    "\n",
    "from decision_rules.classification.ruleset import ClassificationRuleSet\n",
    "from decision_rules.measures import c2, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_inclusion(R, M):\n",
    "  \"\"\"\n",
    "  This function takes two lists, R and M, and returns the result of the equation:\n",
    "\n",
    "  F(R) n F(M) = F(R) U F(M)\n",
    "\n",
    "  where n is the intersection and U is the union of the sets.\n",
    "\n",
    "  Args:\n",
    "    R: A list of elements.\n",
    "    M: A list of elements.\n",
    "\n",
    "  Returns:\n",
    "    A list containing the elements in the intersection and union of R and M.\n",
    "  \"\"\"\n",
    "\n",
    "  # Find the intersection of R and M using a set\n",
    "  intersection = set(R).intersection(set(M))\n",
    "\n",
    "  # Find the union of R and M using the + operator\n",
    "  union = set(R).union(set(M))\n",
    "\n",
    "  # Combine the intersection and union into a single list\n",
    "  result = len(intersection)/len(union) \n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def rmatrix_unique_rules(rule_str, feature_names=None):\n",
    "    features = []\n",
    "    conditions = rule_str.split(\" AND \")\n",
    "    for condition in conditions:\n",
    "        feature_value = condition.split(\" = \")\n",
    "        features.append(feature_value[0])\n",
    "    \n",
    "    return list(pd.unique(features))\n",
    "\n",
    "def anchor_unique_rules(rule_str, feature_names=None):\n",
    "    features = []\n",
    "    conditions = rule_str.split(\" AND \")\n",
    "    for condition in conditions:\n",
    "      for feature in feature_names:\n",
    "        if feature in condition:\n",
    "          features.append(feature)\n",
    "    \n",
    "    return list(pd.unique(features))\n",
    "\n",
    "def extract_shap_fi(shap_df_row, shap_df, shap_length, stat):\n",
    "    row_values = np.abs(shap_df.iloc[shap_df_row,:].values)\n",
    "    col_names = np.array(shap_df.columns)\n",
    "    row_values_sort_idx = np.argsort(-row_values)\n",
    "    if stat == \"all\":\n",
    "      feature_top = list(col_names[row_values_sort_idx])\n",
    "    elif stat == \"max\":\n",
    "      top = np.max(shap_length)\n",
    "      feature_top = list(col_names[row_values_sort_idx])[:top]\n",
    "    elif stat == \"len\":\n",
    "      top = shap_length[shap_df_row]\n",
    "      feature_top = list(col_names[row_values_sort_idx])[:top]\n",
    "    return feature_top\n",
    "\n",
    "def calculate_correlations(fi_rule, fi_bb):\n",
    "    rank_bb = fi_bb.loc[fi_rule][\"bb_rank\"].values\n",
    "\n",
    "    tau = kendalltau(list(range(1,len(fi_rule)+1)), rank_bb)\n",
    "    spearman = spearmanr(list(range(1,len(fi_rule)+1)), rank_bb)\n",
    "    return 0 if np.isnan(tau[0]) else tau[0], 0 if np.isnan(spearman[0]) else spearman[0]\n",
    "\n",
    "def precision(c) -> float:  # pylint: disable=missing-function-docstring\n",
    "    if (c.p + c.n) == 0:\n",
    "        return 0\n",
    "    return c.p / (c.p + c.n)\n",
    "\n",
    "def coverage(c) -> float:  # pylint: disable=missing-function-docstring\n",
    "    return c.p / c.P\n",
    "\n",
    "def shap_rank(shap_df, shap_df_row):\n",
    "    row_values = np.abs(shap_df.iloc[shap_df_row,:].values)\n",
    "    col_names = np.array(shap_df.columns)\n",
    "    shap_bb = pd.DataFrame({'attribute': col_names, 'importance': row_values})\n",
    "\n",
    "    shap_bb = shap_bb.sort_values(by=\"importance\", ascending=False).set_index(\"attribute\")\n",
    "    shap_bb[\"bb_rank\"] = shap_bb[\"importance\"].rank(method=\"min\", ascending=False)\n",
    "\n",
    "    return shap_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_models = pd.read_csv(\"../results/selected_bb_models.csv\")\n",
    "datasets = bb_models[\"dataset\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:11<01:16,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with soybean RF_1\n",
      "Problem with soybean SVC_0\n",
      "Problem with soybean XGB_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:40<00:52,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with semeion RF_0\n",
      "Problem with semeion SVC_0\n",
      "Problem with semeion XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:21<00:52,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with seismic-bumps RF_0\n",
      "Problem with seismic-bumps SVC_0\n",
      "Problem with seismic-bumps XGB_2\n",
      "Problem with madelon RF_1\n",
      "Problem with madelon SVC_0\n",
      "Problem with madelon XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:22<00:36,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with dna RF_1\n",
      "Problem with dna SVC_0\n",
      "Problem with dna XGB_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:22<00:25,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with splice RF_2\n",
      "Problem with splice SVC_0\n",
      "Problem with splice XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:43<01:02,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wilt RF_2\n",
      "Problem with wilt SVC_1\n",
      "Problem with wilt XGB_1\n",
      "Problem with churn SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [03:01<01:09, 17.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with mushroom RF_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [03:43<00:34, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with har RF_2\n",
      "Problem with har SVC_1\n",
      "Problem with har XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:46<00:00, 13.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with nomao RF_2\n",
      "Problem with nomao SVC_0\n",
      "Problem with nomao XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:11<01:14,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with soybean RF_1\n",
      "Problem with soybean SVC_0\n",
      "Problem with soybean XGB_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:40<00:52,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with semeion RF_0\n",
      "Problem with semeion SVC_0\n",
      "Problem with semeion XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:21<00:52,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with seismic-bumps RF_0\n",
      "Problem with seismic-bumps SVC_0\n",
      "Problem with seismic-bumps XGB_2\n",
      "Problem with madelon RF_1\n",
      "Problem with madelon SVC_0\n",
      "Problem with madelon XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:22<00:36,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with dna RF_1\n",
      "Problem with dna SVC_0\n",
      "Problem with dna XGB_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:22<00:25,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with splice RF_2\n",
      "Problem with splice SVC_0\n",
      "Problem with splice XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:45<01:05,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wilt RF_2\n",
      "Problem with wilt SVC_1\n",
      "Problem with wilt XGB_1\n",
      "Problem with churn SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [03:00<01:07, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with mushroom RF_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [03:48<00:36, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with har RF_2\n",
      "Problem with har SVC_1\n",
      "Problem with har XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [07:03<00:00, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with nomao RF_2\n",
      "Problem with nomao SVC_0\n",
      "Problem with nomao XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_types = [\"_filterFF_c2_global\", \"_filterFF_precision_global\"]\n",
    "\n",
    "results_all = pd.DataFrame()\n",
    "\n",
    "for class_type in class_types:\n",
    "\n",
    "    for dataset_path in tqdm(datasets):\n",
    "\n",
    "        models = np.unique(bb_models[bb_models[\"dataset\"] == dataset_path][\"model\"])\n",
    "\n",
    "        x_train_df = pd.read_csv(f\"../results_all/{dataset_path}/train.csv\")\n",
    "        x_train_df = x_train_df.rename(columns={'target': 'name'})\n",
    "        y_train = x_train_df[\"name\"].squeeze().astype(str)\n",
    "        x_train_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        x_test_df = pd.read_csv(f\"../results_all/{dataset_path}/test.csv\")\n",
    "        x_test_df = x_test_df.rename(columns={'target': 'name'})\n",
    "        y_test = x_test_df[\"name\"].squeeze().astype(str)\n",
    "        x_test_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        binary_columns = list(x_train_df.columns[x_train_df.isin([0,1]).all()])\n",
    "        if len(binary_columns) > 0:\n",
    "            x_train_df[binary_columns] = x_train_df[binary_columns].astype(str)\n",
    "            x_test_df[binary_columns] = x_test_df[binary_columns].astype(str)\n",
    "\n",
    "        feature_names = x_train_df.columns\n",
    "\n",
    "        for model_path in models:\n",
    "\n",
    "            fi_path = f\"../results_new/{dataset_path}/{model_path}/fi_test.csv\"\n",
    "            file_path= f\"../results_all/{dataset_path}/{model_path}/ruleset{class_type}.json\"\n",
    "            anchor_path = f\"../results_anchor_all/{dataset_path}/{model_path}/anchor_train.csv\"\n",
    "            \n",
    "            if os.path.exists(fi_path) and os.path.exists(file_path) and os.path.exists(anchor_path):\n",
    "\n",
    "                anchor_train = pd.read_csv(anchor_path, sep=\";\")\n",
    "                anchor_test = pd.read_csv(f\"../results_anchor_all/{dataset_path}/{model_path}/anchor_test.csv\", sep=\";\")\n",
    "\n",
    "                fi = pd.read_csv(fi_path)\n",
    "                fi = fi.sort_values(\"importance\", ascending=False).set_index(\"attribute\")\n",
    "                fi[\"bb_rank\"] = fi[\"importance\"].rank(method=\"min\", ascending=False)\n",
    "                features = list(fi.index)\n",
    "                \n",
    "                with open(file_path, 'r') as json_file:\n",
    "                    ruleset_json_read = json.load(json_file)\n",
    "\n",
    "                classifier = JSONSerializer.deserialize(ruleset_json_read, target_class=ClassificationRuleSet)\n",
    "                if \"c2\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=c2)\n",
    "                elif \"precision\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=precision)\n",
    "\n",
    "                rmatrix_rules = [rule.premise.to_string(feature_names) for rule in classifier.rules]\n",
    "                rmatrix_precision = [precision(rule.coverage) for rule in classifier.rules]\n",
    "                rmatrix_coverage = [coverage(rule.coverage) for rule in classifier.rules]\n",
    "                anchor_rules = anchor_train[\"anchor_rule\"].values\n",
    "\n",
    "                mi_rmatrix_anchor = [mutual_inclusion(rmatrix_unique_rules(rmatrix_rules[obs], features), anchor_unique_rules(anchor_rules[obs], features)) for obs in range(len(rmatrix_rules))]\n",
    "\n",
    "                rmatrix_length = [len(rmatrix_unique_rules(rule, features)) for rule in rmatrix_rules]\n",
    "                mi_rmatrix_fi_all = [mutual_inclusion(rmatrix_unique_rules(rmatrix_rules[obs], features), features) for obs in range(len(rmatrix_rules))]\n",
    "                mi_rmatrix_fi_len = [mutual_inclusion(rmatrix_unique_rules(rmatrix_rules[obs], features), features[:rmatrix_length[obs]]) for obs in range(len(rmatrix_rules))]\n",
    "\n",
    "                anchor_length = [len(anchor_unique_rules(rule, features)) for rule in anchor_rules]\n",
    "                mi_anchor_fi_all = [mutual_inclusion(anchor_unique_rules(anchor_rules[obs], features), features) for obs in range(len(anchor_rules))]\n",
    "                mi_anchor_fi_len = [mutual_inclusion(anchor_unique_rules(anchor_rules[obs], features), features[:anchor_length[obs]]) for obs in range(len(anchor_rules))]\n",
    "\n",
    "                corr_rmatrix = [calculate_correlations(rmatrix_unique_rules(rmatrix_rules[obs], features), fi) for obs in range(len(rmatrix_rules))]                \n",
    "                corr_tau_rmatrix = [cor[0] for cor in corr_rmatrix]\n",
    "                corr_sro_rmatrix = [cor[1] for cor in corr_rmatrix]\n",
    "\n",
    "                corr_anchor = [calculate_correlations(anchor_unique_rules(anchor_rules[obs], features), fi) for obs in range(len(anchor_rules))]                    \n",
    "                corr_tau_anchor = [cor[0] for cor in corr_anchor]\n",
    "                corr_sro_anchor = [cor[1] for cor in corr_anchor]\n",
    "\n",
    "                results = pd.DataFrame({'mi_rmatrix_anchor': mi_rmatrix_anchor, \n",
    "                                        'mi_rmatrix_fi_all': mi_rmatrix_fi_all, 'mi_rmatrix_fi_len': mi_rmatrix_fi_len,\n",
    "                                        'mi_anchor_fi_all': mi_anchor_fi_all, 'mi_anchor_fi_len': mi_anchor_fi_len,\n",
    "                                        'corr_tau_rmatrix': corr_tau_rmatrix, 'corr_tau_anchor': corr_tau_anchor,\n",
    "                                        'rmatrix_precision': rmatrix_precision, 'rmatrix_coverage': rmatrix_coverage,\n",
    "                                        'anchor_precision': anchor_train[\"anchor_precision_correct\"].values, \n",
    "                                        'anchor_coverage': anchor_train[\"anchor_coverage_correct\"].values\n",
    "                                    })\n",
    "                \n",
    "                results[\"dataset\"] = dataset_path\n",
    "                results[\"model\"] = model_path\n",
    "                results[\"measure\"] = class_type.split(\"_\")[2]\n",
    "                results_all = pd.concat([results_all, results])\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(f\"Problem with {dataset_path} {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(results_all[\"dataset\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all.to_csv(f\"../results_anchor_all/anchor_mi_corr_all_global.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with cylinder-bands SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:03<01:48,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wdbc SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:07<01:41,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with kdd-synthetic-control SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:11<01:41,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with balance-scale SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:15<01:40,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with soybean RF_1\n",
      "Problem with soybean SVC_0\n",
      "Problem with soybean XGB_0\n",
      "Problem with credit-a SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:19<01:12,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with breast-w SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:24<01:17,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with diabetes SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:28<01:23,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with vehicle SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:34<01:30,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with tic-tac-toe SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:41<01:40,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with mammographic-masses SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:47<01:40,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with qsar-biodeg SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:54<01:10,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with semeion RF_0\n",
      "Problem with semeion SVC_0\n",
      "Problem with semeion XGB_1\n",
      "Problem with car SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:06<01:41,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with cmc SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:20<02:11,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with titanic SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:34<02:22, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with segment SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:49<01:09,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with seismic-bumps RF_0\n",
      "Problem with seismic-bumps SVC_0\n",
      "Problem with seismic-bumps XGB_2\n",
      "Problem with madelon RF_1\n",
      "Problem with madelon SVC_0\n",
      "Problem with madelon XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:49<00:48,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with dna RF_1\n",
      "Problem with dna SVC_0\n",
      "Problem with dna XGB_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:50<00:33,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with splice RF_2\n",
      "Problem with splice SVC_0\n",
      "Problem with splice XGB_1\n",
      "Problem with kr-vs-kp SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [02:15<01:17,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wilt RF_2\n",
      "Problem with wilt SVC_1\n",
      "Problem with wilt XGB_1\n",
      "Problem with churn SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [02:54<01:24, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with phoneme SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [03:32<01:37, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wall-robot-navigation SVC_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [04:09<01:36, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with mushroom RF_1\n",
      "Problem with mushroom SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [04:49<00:41, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with har RF_2\n",
      "Problem with har SVC_1\n",
      "Problem with har XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [06:18<00:39, 39.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with nursery SVC_0\n",
      "Problem with nursery XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:18<00:00, 12.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with nomao RF_2\n",
      "Problem with nomao SVC_0\n",
      "Problem with nomao XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with cylinder-bands SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:03<01:46,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wdbc SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:07<01:39,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with kdd-synthetic-control SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:11<01:40,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with balance-scale SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:15<01:38,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with soybean RF_1\n",
      "Problem with soybean SVC_0\n",
      "Problem with soybean XGB_0\n",
      "Problem with credit-a SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:19<01:12,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with breast-w SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:24<01:18,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with diabetes SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:28<01:23,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with vehicle SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:34<01:30,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with tic-tac-toe SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:41<01:40,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with mammographic-masses SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:47<01:41,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with qsar-biodeg SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:54<01:10,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with semeion RF_0\n",
      "Problem with semeion SVC_0\n",
      "Problem with semeion XGB_1\n",
      "Problem with car SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:05<01:41,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with cmc SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:20<02:09,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with titanic SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:34<02:25, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with segment SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:49<01:10,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with seismic-bumps RF_0\n",
      "Problem with seismic-bumps SVC_0\n",
      "Problem with seismic-bumps XGB_2\n",
      "Problem with madelon RF_1\n",
      "Problem with madelon SVC_0\n",
      "Problem with madelon XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:49<00:48,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with dna RF_1\n",
      "Problem with dna SVC_0\n",
      "Problem with dna XGB_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:50<00:33,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with splice RF_2\n",
      "Problem with splice SVC_0\n",
      "Problem with splice XGB_1\n",
      "Problem with kr-vs-kp SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [02:16<01:18,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wilt RF_2\n",
      "Problem with wilt SVC_1\n",
      "Problem with wilt XGB_1\n",
      "Problem with churn SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [02:55<01:24, 14.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with phoneme SVC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [03:31<01:36, 19.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with wall-robot-navigation SVC_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [04:09<01:35, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with mushroom RF_1\n",
      "Problem with mushroom SVC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [04:51<00:41, 20.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with har RF_2\n",
      "Problem with har SVC_1\n",
      "Problem with har XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [06:24<00:41, 41.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with nursery SVC_0\n",
      "Problem with nursery XGB_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:24<00:00, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with nomao RF_2\n",
      "Problem with nomao SVC_0\n",
      "Problem with nomao XGB_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_types = [\"_filterFF_c2_local\", \"_filterFF_precision_local\"]\n",
    "\n",
    "results_all = pd.DataFrame()\n",
    "\n",
    "for class_type in class_types:\n",
    "\n",
    "    for dataset_path in tqdm(datasets):\n",
    "\n",
    "        models = np.unique(bb_models[bb_models[\"dataset\"] == dataset_path][\"model\"])\n",
    "\n",
    "        x_train_df = pd.read_csv(f\"../results_all/{dataset_path}/train.csv\")\n",
    "        x_train_df = x_train_df.rename(columns={'target': 'name'})\n",
    "        y_train = x_train_df[\"name\"].squeeze().astype(str)\n",
    "        x_train_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        x_test_df = pd.read_csv(f\"../results_all/{dataset_path}/test.csv\")\n",
    "        x_test_df = x_test_df.rename(columns={'target': 'name'})\n",
    "        y_test = x_test_df[\"name\"].squeeze().astype(str)\n",
    "        x_test_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        binary_columns = list(x_train_df.columns[x_train_df.isin([0,1]).all()])\n",
    "        if len(binary_columns) > 0:\n",
    "            x_train_df[binary_columns] = x_train_df[binary_columns].astype(str)\n",
    "            x_test_df[binary_columns] = x_test_df[binary_columns].astype(str)\n",
    "\n",
    "        feature_names = x_train_df.columns\n",
    "\n",
    "        for model_path in models:\n",
    "\n",
    "            shap_path = f\"../results_all/{dataset_path}/{model_path}/shap.csv\"\n",
    "            file_path= f\"../results_all/{dataset_path}/{model_path}/ruleset{class_type}.json\"\n",
    "            anchor_path = f\"../results_anchor_all/{dataset_path}/{model_path}/anchor_train.csv\"\n",
    "            \n",
    "            if os.path.exists(shap_path) and os.path.exists(file_path) and os.path.exists(anchor_path):\n",
    "\n",
    "                anchor_train = pd.read_csv(anchor_path, sep=\";\")\n",
    "                anchor_test = pd.read_csv(f\"../results_anchor_all/{dataset_path}/{model_path}/anchor_test.csv\", sep=\";\")\n",
    "\n",
    "                shap = pd.read_csv(shap_path)\n",
    "                \n",
    "                with open(file_path, 'r') as json_file:\n",
    "                    ruleset_json_read = json.load(json_file)\n",
    "\n",
    "                classifier = JSONSerializer.deserialize(ruleset_json_read, target_class=ClassificationRuleSet)\n",
    "                if \"c2\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=c2)\n",
    "                elif \"precision\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=precision)\n",
    "\n",
    "                rmatrix_rules = [rule.premise.to_string(feature_names) for rule in classifier.rules]\n",
    "                rmatrix_precision = [precision(rule.coverage) for rule in classifier.rules]\n",
    "                rmatrix_coverage = [coverage(rule.coverage) for rule in classifier.rules]\n",
    "                anchor_rules = anchor_train[\"anchor_rule\"].values\n",
    "\n",
    "                rules_features = [rmatrix_unique_rules(rule, feature_names) for rule in rmatrix_rules]\n",
    "                rules_lengths = [len(rule) for rule in rules_features]\n",
    "\n",
    "                shap_features = [extract_shap_fi(row, shap, rules_lengths, stat = \"all\") for row in range(len(shap))]                  \n",
    "                shap_features_max = [extract_shap_fi(row, shap, rules_lengths, stat = \"max\") for row in range(len(shap))]\n",
    "                shap_features_len = [extract_shap_fi(row, shap, rules_lengths, stat = \"len\") for row in range(len(shap))]\n",
    "\n",
    "                mi_rmatrix_anchor = [mutual_inclusion(rmatrix_unique_rules(rmatrix_rules[obs], feature_names), anchor_unique_rules(anchor_rules[obs], feature_names)) for obs in range(len(rmatrix_rules))]\n",
    "\n",
    "                rmatrix_length = [len(rmatrix_unique_rules(rule, feature_names)) for rule in rmatrix_rules]\n",
    "                mi_rmatrix_fi_all = [mutual_inclusion(rmatrix_unique_rules(rmatrix_rules[obs], feature_names), shap_features[obs]) for obs in range(len(rmatrix_rules))]\n",
    "                mi_rmatrix_fi_len = [mutual_inclusion(rmatrix_unique_rules(rmatrix_rules[obs], feature_names), shap_features_len[obs]) for obs in range(len(rmatrix_rules))]\n",
    "\n",
    "                anchor_length = [len(anchor_unique_rules(rule, feature_names)) for rule in anchor_rules]\n",
    "                mi_anchor_fi_all = [mutual_inclusion(anchor_unique_rules(anchor_rules[obs], feature_names), shap_features[obs]) for obs in range(len(anchor_rules))]\n",
    "                mi_anchor_fi_len = [mutual_inclusion(anchor_unique_rules(anchor_rules[obs], feature_names), shap_features_len[obs]) for obs in range(len(anchor_rules))]\n",
    "\n",
    "                corr_rmatrix = [calculate_correlations(rmatrix_unique_rules(rmatrix_rules[obs], feature_names), shap_rank(shap, obs)) for obs in range(len(rmatrix_rules))]                \n",
    "                corr_tau_rmatrix = [cor[0] for cor in corr_rmatrix]\n",
    "                corr_sro_rmatrix = [cor[1] for cor in corr_rmatrix]\n",
    "\n",
    "                corr_anchor = [calculate_correlations(anchor_unique_rules(anchor_rules[obs], feature_names), shap_rank(shap, obs)) for obs in range(len(anchor_rules))]                    \n",
    "                corr_tau_anchor = [cor[0] for cor in corr_anchor]\n",
    "                corr_sro_anchor = [cor[1] for cor in corr_anchor]\n",
    "\n",
    "                results = pd.DataFrame({'mi_rmatrix_anchor': mi_rmatrix_anchor, \n",
    "                                        'mi_rmatrix_fi_all': mi_rmatrix_fi_all, 'mi_rmatrix_fi_len': mi_rmatrix_fi_len,\n",
    "                                        'mi_anchor_fi_all': mi_anchor_fi_all, 'mi_anchor_fi_len': mi_anchor_fi_len,\n",
    "                                        'corr_tau_rmatrix': corr_tau_rmatrix, 'corr_tau_anchor': corr_tau_anchor,\n",
    "                                        'rmatrix_precision': rmatrix_precision, 'rmatrix_coverage': rmatrix_coverage,\n",
    "                                        'anchor_precision': anchor_train[\"anchor_precision_correct\"].values, \n",
    "                                        'anchor_coverage': anchor_train[\"anchor_coverage_correct\"].values\n",
    "                                    })\n",
    "                \n",
    "                results[\"dataset\"] = dataset_path\n",
    "                results[\"model\"] = model_path\n",
    "                results[\"measure\"] = class_type.split(\"_\")[2]\n",
    "                results_all = pd.concat([results_all, results])\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(f\"Problem with {dataset_path} {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all.to_csv(f\"../results_anchor_all/anchor_mi_corr_all_local.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
