{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, balanced_accuracy_score, recall_score, mutual_info_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rmatrix.classification import RMatrixClassifier\n",
    "from decision_rules.serialization.utils import JSONSerializer\n",
    "from decision_rules.classification.ruleset import ClassificationRuleSet\n",
    "from decision_rules.measures import c2, precision\n",
    "\n",
    "from scipy.stats import kendalltau, spearmanr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_inclusion(R, M):\n",
    "  \"\"\"\n",
    "  This function takes two lists, R and M, and returns the result of the equation:\n",
    "\n",
    "  F(R) n F(M) = F(R) U F(M)\n",
    "\n",
    "  where n is the intersection and U is the union of the sets.\n",
    "\n",
    "  Args:\n",
    "    R: A list of elements.\n",
    "    M: A list of elements.\n",
    "\n",
    "  Returns:\n",
    "    A list containing the elements in the intersection and union of R and M.\n",
    "  \"\"\"\n",
    "\n",
    "  # Find the intersection of R and M using a set\n",
    "  intersection = set(R).intersection(set(M))\n",
    "\n",
    "  # Find the union of R and M using the + operator\n",
    "  union = set(R).union(set(M))\n",
    "\n",
    "  # Combine the intersection and union into a single list\n",
    "  result = len(intersection)/len(union) \n",
    "\n",
    "  return result\n",
    "\n",
    "def rmatrix_unique_rules(rule, feature_names=None):\n",
    "    rule_str = rule.premise.to_string(feature_names)\n",
    "    features = []\n",
    "    conditions = rule_str.split(\" AND \")\n",
    "    for condition in conditions:\n",
    "        feature_value = condition.split(\" = \")\n",
    "        features.append(feature_value[0])\n",
    "    \n",
    "    return list(pd.unique(features))\n",
    "\n",
    "def extract_shap_fi(shap_df_row, shap_df, shap_length, stat):\n",
    "    row_values = np.abs(shap_df.iloc[shap_df_row,:].values)\n",
    "    col_names = np.array(shap_df.columns)\n",
    "    row_values_sort_idx = np.argsort(-row_values)\n",
    "    if stat == \"all\":\n",
    "      feature_top = list(col_names[row_values_sort_idx])\n",
    "    elif stat == \"max\":\n",
    "      top = np.max(shap_length)\n",
    "      feature_top = list(col_names[row_values_sort_idx])[:top]\n",
    "    elif stat == \"len\":\n",
    "      top = shap_length[shap_df_row]\n",
    "      feature_top = list(col_names[row_values_sort_idx])[:top]\n",
    "    return feature_top\n",
    "\n",
    "def precision(c) -> float:  # pylint: disable=missing-function-docstring\n",
    "    if (c.p + c.n) == 0:\n",
    "        return 0\n",
    "    return c.p / (c.p + c.n)\n",
    "\n",
    "def coverage(c) -> float:  # pylint: disable=missing-function-docstring\n",
    "    return c.p / c.P\n",
    "\n",
    "def calculate_correlations(fi_rule, fi_bb):\n",
    "    fi_bb = fi_bb.sort_values(by=\"importance\", ascending=False)\n",
    "    fi_bb[\"bb_rank\"] = fi_bb[\"importance\"].rank(method=\"min\", ascending=False)\n",
    "    # fi_bb_top = fi_bb.iloc[:fi_length,:]\n",
    "\n",
    "    fi_rules = pd.DataFrame({'attribute': fi_rule})\n",
    "    fi_rules[\"rule_rank\"] = fi_rules.index+1\n",
    "\n",
    "    fi_rules_bb = fi_rules.merge(fi_bb, how=\"left\", on=\"attribute\")\n",
    "\n",
    "    tau = kendalltau(fi_rules_bb[\"rule_rank\"], fi_rules_bb[\"bb_rank\"])\n",
    "    spearman = spearmanr(fi_rules_bb[\"rule_rank\"], fi_rules_bb[\"bb_rank\"])\n",
    "    return 0 if np.isnan(tau[0]) else tau[0], 0 if np.isnan(spearman[0]) else spearman[0]\n",
    "\n",
    "def calculate_correlations2(fi_rule, fi_bb):\n",
    "    rank_bb = fi_bb.loc[fi_rule][\"bb_rank\"].values\n",
    "\n",
    "    tau = kendalltau(list(range(1,len(fi_rule)+1)), rank_bb)\n",
    "    spearman = spearmanr(list(range(1,len(fi_rule)+1)), rank_bb)\n",
    "    return 0 if np.isnan(tau[0]) else tau[0], 0 if np.isnan(spearman[0]) else spearman[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_models = pd.read_csv(\"results/selected_bb_models.csv\")\n",
    "datasets = bb_models[\"dataset\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMatrix without ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = [\"_filterFF_precision_approx\"]\n",
    "\n",
    "results_all = pd.DataFrame()\n",
    "results_detailed = pd.DataFrame()\n",
    "\n",
    "for class_type in class_types:\n",
    "\n",
    "    for sel_dataset in tqdm(datasets):\n",
    "\n",
    "        models = np.unique(bb_models[bb_models[\"dataset\"]==sel_dataset][\"model\"])\n",
    "\n",
    "        x_train_df = pd.read_csv(f\"../results_all/{sel_dataset}/train.csv\")\n",
    "        x_train_df = x_train_df.rename(columns={'target': 'name'})\n",
    "        y_train = x_train_df[\"name\"].squeeze().astype(str)\n",
    "        x_train_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        x_test_df = pd.read_csv(f\"../results_all/{sel_dataset}/test.csv\")\n",
    "        x_test_df = x_test_df.rename(columns={'target': 'name'})\n",
    "        y_test = x_test_df[\"name\"].squeeze().astype(str)\n",
    "        x_test_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        binary_columns = list(x_train_df.columns[x_train_df.isin([0,1]).all()])\n",
    "        if len(binary_columns) > 0:\n",
    "            x_train_df[binary_columns] = x_train_df[binary_columns].astype(str)\n",
    "            x_test_df[binary_columns] = x_test_df[binary_columns].astype(str)\n",
    "\n",
    "        feature_names = x_train_df.columns\n",
    "\n",
    "        for sel_model in models:\n",
    "\n",
    "            fi_path = f\"../results_new/{sel_dataset}/{sel_model}/fi_test.csv\"\n",
    "            file_path= f\"../results_all/{sel_dataset}/{sel_model}/ruleset{class_type}.json\"\n",
    "\n",
    "            if os.path.exists(fi_path) and os.path.exists(file_path):\n",
    "\n",
    "                fi = pd.read_csv(fi_path)\n",
    "                fi_bb = fi.sort_values(by=\"importance\", ascending=False).set_index(\"attribute\")\n",
    "                fi_bb[\"bb_rank\"] = fi_bb[\"importance\"].rank(method=\"min\", ascending=False)\n",
    "\n",
    "                with open(file_path, 'r') as json_file:\n",
    "                    ruleset_json_read = json.load(json_file)\n",
    "\n",
    "                classifier = JSONSerializer.deserialize(ruleset_json_read, target_class=ClassificationRuleSet)\n",
    "                if \"c2\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=c2)\n",
    "                elif \"precision\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=precision)\n",
    "\n",
    "                rules_features = [rmatrix_unique_rules(rule, feature_names) for rule in classifier.rules]\n",
    "                rules_lengths = [len(rule) for rule in rules_features]\n",
    "                \n",
    "                corr_all = [calculate_correlations2(rules_features[obs], fi_bb) for obs in range(len(rules_features))]\n",
    "                \n",
    "                corr_tau_all = [cor[0] for cor in corr_all]\n",
    "                corr_sro_all = [cor[1] for cor in corr_all]\n",
    "                \n",
    "                corr_df = pd.DataFrame({'corr_tau_all': corr_tau_all, 'corr_sro_all': corr_sro_all})\n",
    "                corr_df[\"dataset\"] = sel_dataset\n",
    "                corr_df[\"model\"] = sel_model\n",
    "                corr_df[\"rmatrix\"] = \"c2\" if \"c2\" in class_type else \"precision\"\n",
    "\n",
    "                results_all = pd.concat([results_all, corr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all.to_csv(\"results/corr_without_fi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMatrix with global ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = [\"_filterFF_precision_global\"]\n",
    "\n",
    "results_all = pd.DataFrame()\n",
    "results_detailed = pd.DataFrame()\n",
    "\n",
    "for class_type in class_types:\n",
    "\n",
    "    for sel_dataset in tqdm(datasets):\n",
    "\n",
    "        models = np.unique(bb_models[bb_models[\"dataset\"]==sel_dataset][\"model\"])\n",
    "\n",
    "        x_train_df = pd.read_csv(f\"../results_all/{sel_dataset}/train.csv\")\n",
    "        x_train_df = x_train_df.rename(columns={'target': 'name'})\n",
    "        y_train = x_train_df[\"name\"].squeeze().astype(str)\n",
    "        x_train_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        x_test_df = pd.read_csv(f\"../results_all/{sel_dataset}/test.csv\")\n",
    "        x_test_df = x_test_df.rename(columns={'target': 'name'})\n",
    "        y_test = x_test_df[\"name\"].squeeze().astype(str)\n",
    "        x_test_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        binary_columns = list(x_train_df.columns[x_train_df.isin([0,1]).all()])\n",
    "        if len(binary_columns) > 0:\n",
    "            x_train_df[binary_columns] = x_train_df[binary_columns].astype(str)\n",
    "            x_test_df[binary_columns] = x_test_df[binary_columns].astype(str)\n",
    "\n",
    "        feature_names = x_train_df.columns\n",
    "\n",
    "        for sel_model in models:\n",
    "\n",
    "            fi_path = f\"../results_new/{sel_dataset}/{sel_model}/fi_test.csv\"\n",
    "            file_path= f\"../results_all/{sel_dataset}/{sel_model}/ruleset{class_type}.json\"\n",
    "\n",
    "            if os.path.exists(fi_path) and os.path.exists(file_path):\n",
    "\n",
    "                fi = pd.read_csv(fi_path)\n",
    "                fi_bb = fi.sort_values(by=\"importance\", ascending=False).set_index(\"attribute\")\n",
    "                fi_bb[\"bb_rank\"] = fi_bb[\"importance\"].rank(method=\"min\", ascending=False)\n",
    "\n",
    "                with open(file_path, 'r') as json_file:\n",
    "                    ruleset_json_read = json.load(json_file)\n",
    "\n",
    "                classifier = JSONSerializer.deserialize(ruleset_json_read, target_class=ClassificationRuleSet)\n",
    "                if \"c2\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=c2)\n",
    "                elif \"precision\" in class_type:\n",
    "                    classifier.update(x_train_df, y_train, measure=precision)\n",
    "\n",
    "                rules_features = [rmatrix_unique_rules(rule, feature_names) for rule in classifier.rules]\n",
    "                rules_lengths = [len(rule) for rule in rules_features]\n",
    "                \n",
    "                corr_all = [calculate_correlations2(rules_features[obs], fi_bb) for obs in range(len(rules_features))]\n",
    "                \n",
    "                corr_tau_all = [cor[0] for cor in corr_all]\n",
    "                corr_sro_all = [cor[1] for cor in corr_all]\n",
    "                \n",
    "                corr_df = pd.DataFrame({'corr_tau_all': corr_tau_all, 'corr_sro_all': corr_sro_all})\n",
    "                corr_df[\"dataset\"] = sel_dataset\n",
    "                corr_df[\"model\"] = sel_model\n",
    "                corr_df[\"rmatrix\"] = \"c2\" if \"c2\" in class_type else \"precision\"\n",
    "\n",
    "                results_all = pd.concat([results_all, corr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all.to_csv(\"results/corr_with_fi_global.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMatrix with local ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_rank(shap_df, shap_df_row):\n",
    "    row_values = np.abs(shap_df.iloc[shap_df_row,:].values)\n",
    "    col_names = np.array(shap_df.columns)\n",
    "    shap_bb = pd.DataFrame({'attribute': col_names, 'importance': row_values})\n",
    "\n",
    "    shap_bb = shap_bb.sort_values(by=\"importance\", ascending=False).set_index(\"attribute\")\n",
    "    shap_bb[\"bb_rank\"] = shap_bb[\"importance\"].rank(method=\"min\", ascending=False)\n",
    "\n",
    "    return shap_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = [\"_filterFF_precision_local\"]\n",
    "\n",
    "results_all = pd.DataFrame()\n",
    "results_detailed = pd.DataFrame()\n",
    "\n",
    "for class_type in class_types:\n",
    "\n",
    "    for sel_dataset in tqdm(datasets):\n",
    "\n",
    "        models = np.unique(bb_models[bb_models[\"dataset\"]==sel_dataset][\"model\"])\n",
    "\n",
    "        x_train_df = pd.read_csv(f\"../results_all/{sel_dataset}/train.csv\")\n",
    "        x_train_df = x_train_df.rename(columns={'target': 'name'})\n",
    "        y_train = x_train_df[\"name\"].squeeze().astype(str)\n",
    "        x_train_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        x_test_df = pd.read_csv(f\"../results_all/{sel_dataset}/test.csv\")\n",
    "        x_test_df = x_test_df.rename(columns={'target': 'name'})\n",
    "        y_test = x_test_df[\"name\"].squeeze().astype(str)\n",
    "        x_test_df.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "        binary_columns = list(x_train_df.columns[x_train_df.isin([0,1]).all()])\n",
    "        if len(binary_columns) > 0:\n",
    "            x_train_df[binary_columns] = x_train_df[binary_columns].astype(str)\n",
    "            x_test_df[binary_columns] = x_test_df[binary_columns].astype(str)\n",
    "\n",
    "        feature_names = x_train_df.columns\n",
    "\n",
    "        for sel_model in models:\n",
    "\n",
    "            if sel_model.split(\"_\")[0] != 'SVC':\n",
    "\n",
    "                shap_path = f\"../results_all/{sel_dataset}/{sel_model}/shap.csv\"\n",
    "                file_path= f\"../results_all/{sel_dataset}/{sel_model}/ruleset{class_type}.json\"\n",
    "\n",
    "                if os.path.exists(shap_path) and os.path.exists(file_path):\n",
    "\n",
    "                    shap = pd.read_csv(shap_path)\n",
    "                    \n",
    "                    with open(file_path, 'r') as json_file:\n",
    "                        ruleset_json_read = json.load(json_file)\n",
    "\n",
    "                    classifier = JSONSerializer.deserialize(ruleset_json_read, target_class=ClassificationRuleSet)\n",
    "                    if \"c2\" in class_type:\n",
    "                        classifier.update(x_train_df, y_train, measure=c2)\n",
    "                    elif \"precision\" in class_type:\n",
    "                        classifier.update(x_train_df, y_train, measure=precision)\n",
    "\n",
    "                    rules_features = [rmatrix_unique_rules(rule, feature_names) for rule in classifier.rules]\n",
    "                    rules_lengths = [len(rule) for rule in rules_features]\n",
    "                    \n",
    "                    corr_all = [calculate_correlations2(rules_features[obs], shap_rank(shap, obs)) for obs in range(len(rules_features))]\n",
    "                    \n",
    "                    corr_tau_all = [cor[0] for cor in corr_all]\n",
    "                    corr_sro_all = [cor[1] for cor in corr_all]\n",
    "                    \n",
    "                    corr_df = pd.DataFrame({'corr_tau_all': corr_tau_all, 'corr_sro_all': corr_sro_all})\n",
    "                    corr_df[\"dataset\"] = sel_dataset\n",
    "                    corr_df[\"model\"] = sel_model\n",
    "                    corr_df[\"rmatrix\"] = \"c2\" if \"c2\" in class_type else \"precision\"\n",
    "\n",
    "                    results_all = pd.concat([results_all, corr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all.to_csv(\"results/corr_with_fi_local.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-srv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
